\documentclass{article}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{geometry}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{float}
\usepackage[useregional]{datetime2}
\usepackage{url}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
\usepackage[font=small,skip=0pt]{caption}
\geometry{legalpaper, margin=1in}
\title{A Shallow Study on Rumble Strips' Effectiveness on Different Road Conditions}
\author{Zhijia Chen}
\date{\today}

\begin{document}

\begin{titlepage}
    \maketitle
\end{titlepage}

\section*{Summary}
Rumble strips has been widely adopted as an economic measure to alert inattentive drivers of potential dangers. A rumble strip is a raised or grooved pattern on travel lanes and has different texture with the road on with it is installed. When vehicle tires pass over the strip, they produce a sudden rumbling sound and cause the automobile to vibrate so as to alert inattentive or drowsy drivers[]. It is expected that drivers will pay more attention when passing the road and thus reduce the possibility of potential car accidents. A car accident is such a complex random event that contributed by many factors, it is hard to tell how effective rumble strips are in reducing crashes. So, in this study, we explore the effectiveness of rumble strips by comparing the changes in yearly car crashes number between roads with and without rumble installed in an observed time span (2004 to 2012). We find that there isn't strong evidence that rumble stripes have a general effects in reducing average number of crash on all roads. But when we focus on roads with certain condition, such as road curvature, road width, speed limit, etc., we found that on roads with curvature degree greater than 5, rumble strips can prevent \% of car crashes on average. We also find that rumble strips is also likely to reduce ?\% of car crashes on roads of width greater than 24 feet while they have positive effects in narrower roads, which is unexpected as by intuition we think a crash is more likely to happen if the road is narrower. By further investing the annual traffic volume, we realize that wider roads usually hold more traffic volume and thus higher car accident possibility. We also suspect that rumble strips would help on crash-prone roads, i.e., roads with car accident records in 2004, but we didn't find any strong evidence to support that. 

\section*{Dataset and Assumption}

This study works with the dataset "PennCrash.txt"[] that provides number of crashes occurred on about 2000 road segments (sites) in Pennsylvania in the year 2004, 2008 and 2012. Among these sites, rumble strips were installed in 331 of them between year 2008 and 2012. The dataset also gives some features of the roads including annual average daily traffic (AADT) volume, curvature, width, posted speed limit and so on. As we do not know if rumble stripes were installed in 2008 or not, we only use the data of the year 2004 and 2012, and we assume that by the beginning of 2012, all the rumble stripes in this dataset had been installed. Thus we have a clean data to study the crash number before and after rumble strips installation.

\section*{Methodology}

To study if rumble strips help in reducing the number of car crashes, a naive approach is to compare the car accident number before and after rumble strip installation. However, 8 years (2004 to 2012) is quite a long time span and many factors that affect car crash could have changed over time, such as better traffic control system, improved overall driving behavior, better car control system, higher/lower traffic volume, etc., and we cannot simply claim the changes in car crashes as being the effect of rumble stripes. So we take data of roads that do not have rumble strips treatment as a control group, and those that have rumble strips treatment as treat group. We will study the total crash number changes between year 2012 and year 2004 of the two groups, and test the differences between the two population. When investigating rumble strips' effects on roads of particular features, we will filter the data using the corresponding column before testing the differences. 

And to compare two population, we perform single-tailed two sample t-test to test their means are equal and get the p value. Generally, we have the following null hypothesis and alternative hypothesis:

\begin{align*}
    H_0: &Mean(tot12-tot04)|(treat, condition(c_1, c_2, ..., c_n)) >= Mean(tot12-tot04)|(not treat, condition(c_1, c_2, ..., c_n))\\
    H_1: &Mean(tot12-tot04)|(treat, condition(c_1, c_2, ..., c_n)) < Mean(tot12-tot04)|(not treat, condition(c_1, c_2, ..., c_n))\\
\end{align*}

Where $tot04$ and $tot12$ are the total number of crashes in year 2004 and 2012 respectively, and $Mean(tot12-tot04)|(treat, condition(c_1, c_2, ..., c_n))$ denotes the mean value of $tot12-tot04$ of roads that have rumble stripe treatment with conditions on road features $c_1, c_2, ..., c_n$. We set $\alpha$ value to 0.05 in this study.

\section*{Rumble Strips Effectiveness Tests}

We first study rumble strips' effects on all the roads in the dataset regardless of any road features. Figure ~\ref{fig:general-effect} shows the distribution of the two population. The mean value for the population with rumble strips treatment is -0.066 and 0.028 for that without treatment. While the mean value of the treatment group is slightly smaller than the control group, the p value is 0.057 so we accept the null hypothesis. But still, we can see that the distribution at 1 is marginally smaller than the value at -1 in the group with treatment, and the other way around in the other group. This is a good sign that we can find a more significant difference if we refine the two groups with certain condition on some road features.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{with-and-without-rumble-diff.png}
    \caption{distribution of tot12-tot04 on roads with and without rumble treatment}
    \label{fig:general-effect}
\end{figure}

\begin{align*}
    X_t=c+\epsilon_t+\sum_{i=1}^p\phi X_{t-i}+\sum_{i=1}^q\theta_i\epsilon_{t-i}
\end{align*}

Where:
\begin{itemize}
    \item $\phi$ is the autoregressive model's parameters.
    \item $\theta$ is the moving average model's parameters.
    \item c is a constant.
    \item $\epsilon_t$ is the prediction error at time $t$.
\end{itemize}

\textbf{Exploratory Data Analysis}

Figure ~\ref{fig:returns} shows the S\&P 500 annual returns After 1950. We perform a augmented Dickey-Fuller test on the data and the alternative hypothesis indicates that the annual returns is a stationary time series. Figure ~\ref{fig:adf} shows the test result produced by the adf.test function in R.

\begin{figure}[H]
    \centering
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{sp500-annual-increase.jpg}
        \caption{S\&P 500 Annual Returns After 1950}
        \label{fig:returns}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{stationary-test.png}
        \caption{Augmented Dickey-Fuller Test}
        \label{fig:adf}
    \end{subfigure}
    %\caption{A figure with two subfigures}
    %\label{fig:test}
\end{figure}

\vspace{\baselineskip}
\textbf{Model Development and Test}

The most important step in building the $ARMA(p, q)$ model is selecting the autoregression lag order $p$ and the moving average lag order $q$. As we use the MATLAB Econometrics Toolbox to build the model, we follow it's documentation\cite{lags} to plot autocorrelation function(ACF) and partial autocorrelation function to choose potential lags. We also compute the mean of the returns to estimate the constant $c$.

Figure ~\ref{fig:acf} and figure ~\ref{fig:pacf} show the autocorrelation function and partial autocorrelation function of the S\&P 500 annual returns respectively. In the ACF plot, we see that the function shuts off at lag 10, so we choose the first 10 lags as potential lags for the moving average model. And similarly, we only choose those lags that exceeds the confidence bounds (marked by the blue lines) as potential values (1, 2, 4, 5, 6, 9, 10, 13, 14, 25) for the autoregression model.

\begin{figure}
    \centering
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{acf.jpg}
        \caption{autocorrelation function plot}
        \label{fig:acf}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{pacf.jpg}
        \caption{partial autocorrelation function plot}
        \label{fig:pacf}
    \end{subfigure}
    %\caption{A figure with two subfigures}
    %\label{fig:test}
\end{figure}

With potential lags chosen above, we explore the best best combination of the autoregression lags and moving averages lags for model. However, there are $2^{20}$ possible combinations of the choose lags which is impossible for us to do a brutal search, thus we loop through 1 to 10 for the autoregression lag order $p$ and loop through 1 to 25 for the moving average lag order $q$. In each loop of $p_i$ and $q_j$, if both $p_i$ and $q_j$ are in the potential lags for their corresponding models, we then estimate the $ARMA(p_i, q_j)$ model with the chosen lags that within the order using maximum likelihood method. Thus we only need to explore $10\times10=100$ combinations of the lags. Finally, we choose the model that has the minium AIC as our final model which is given below (all the coefficients are rounded to 3 decimal places):

\begin{align*}
    X_t=&0.015X_{t-1}+0.678X_{t-2}-0.602X_{t-4}+0.147X_{t-5}+\\
        &0.263X_{t-6}+0.062X_{t-9}-0.056X_{t-10}-0.153X_{t-13}-0.089X_{t-14}+\\
        &1.108\epsilon_{t-1}+0.261\epsilon_{t-2}+0.140\epsilon_{t-3}+1\epsilon_{t-4}+1\epsilon_{t-5}+\\
        &0.213\epsilon_{t-6}+0.051\epsilon_{t-7}+0.640\epsilon_{t-8}+0.674\epsilon_{t-9}+\\
        &0.10152+\epsilon_t\\
\end{align*}

Figure ~\ref{fig:fit} shows the fitted data and the residual plot. We can see that the model fits the data very well with maximum residual at only around 0.15. The AIC and BIC for the model are also at a very low level which are -2.0673e+03 and -1.9882e+03 respectively.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{fit.jpg}
    \caption{the fitted data and residual plot of the best model}
    \label{fig:fit}
\end{figure}

To test our model, we do a 1-year span forecast and compare it against the actual data. Figure ~\ref{fig:forecast1} presents the forecast data and the error. We notice that the change trend of the forecast generally matches the actual data, but the data change scale diminishes as the time goes which makes the future predication approaching to a constant. Figure ~\ref{fig:forecast10} shows a 10-year forecast and the predicated data indeed level off after 3 years. Overall, the results show that our model is capable of doing a good short term forecast but would need further improvements to increase the reliable forecast span.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{forecast-1-year.jpg}
    \caption{1-year span forecast data and the forecast error}
    \label{fig:forecast1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{forecast-10-year.jpg}
    \caption{1-year span forecast data and the forecast error}
    \label{fig:forecast10}
\end{figure}

\bibliography{project1} 
\bibliographystyle{ieeetr}
\end{document}

